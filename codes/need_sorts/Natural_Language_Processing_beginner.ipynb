{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a633dfd8",
      "metadata": {
        "id": "a633dfd8"
      },
      "source": [
        "### from https://youtu.be/2e9wnwuAVv0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bad7650",
      "metadata": {
        "id": "9bad7650"
      },
      "source": [
        "python3 -m pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c9d892",
      "metadata": {
        "id": "05c9d892"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c2b430",
      "metadata": {
        "id": "e1c2b430"
      },
      "source": [
        "!source ./mecab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abe4ab5",
      "metadata": {
        "id": "1abe4ab5"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1c97b6",
      "metadata": {
        "id": "ae1c97b6"
      },
      "outputs": [],
      "source": [
        "tagger = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cce1818",
      "metadata": {
        "id": "2cce1818",
        "outputId": "9879854d-c440-4225-80e9-30075462ca14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('언제나', 'MAG'),\n",
              " ('현재', 'NNG'),\n",
              " ('에', 'JKB'),\n",
              " ('집중', 'NNG'),\n",
              " ('할', 'XSV+ETM'),\n",
              " ('수', 'NNB'),\n",
              " ('있', 'VV'),\n",
              " ('다면', 'EC'),\n",
              " ('행복', 'NNG'),\n",
              " ('합니다', 'XSA+EF'),\n",
              " ('.', 'SF')]"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"언제나 현재에 집중할 수  있다면 행복합니다.\"\n",
        "tagger.pos(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a778056b",
      "metadata": {
        "id": "a778056b",
        "outputId": "61be0a42-1353-42f3-ba51-456488e6d332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['언제나', '현재', '에', '집중', '할', '수', '있', '다면', '행복', '합니다', '.']"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tagger.morphs(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be55ef9f",
      "metadata": {
        "id": "be55ef9f",
        "outputId": "1f44b36c-a7fa-46f2-d31f-80f1a7b8e4f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['현재', '집중', '수', '행복']"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tagger.nouns(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6e7e1b",
      "metadata": {
        "id": "0a6e7e1b"
      },
      "source": [
        "python3 -m pip install kss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12ee53b",
      "metadata": {
        "id": "d12ee53b",
        "outputId": "2dff7d7f-a818-4441-db85-5f2c29997d37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['진짜? 내일 뭐하지.', '이렇게 애매모호한 문장도? 가능하다고 보이지 않아.', '나는...']"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import kss\n",
        "text = '진짜? 내일 뭐하지. 이렇게 애매모호한 문장도? 가능하다고 보이지 않아. 나는...'\n",
        "kss.split_sentences(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef9659a",
      "metadata": {
        "id": "cef9659a",
        "outputId": "c82c446a-7a2a-440b-85b6-375a6911202d"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install nltk konlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf723cb1",
      "metadata": {
        "id": "bf723cb1",
        "outputId": "5bcf6afd-e9f6-4d37-a4b6-28a8d4d1fa64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['안년하세요 ', ' 저는 자연어 처리(Natural Language Processing)', '!! 배우고 있습니다.']"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "sentence = '안년하세요 ㅋㅋ 저는 자연어 처리(Natural Language Processing)ㄹ!! 배우고 있습니다.'\n",
        "# tokenizer = RegexpTokenizer('[가-힣]+', gaps=True)\n",
        "# [' ㅋㅋ ', ' ', ' ', '(Natural Language Processing)ㄹ!! ', ' ', '.']\n",
        "tokenizer = RegexpTokenizer('[ㄱ-ㅎ]+', gaps=True)\n",
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48fe9cb1",
      "metadata": {
        "id": "48fe9cb1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264532f1",
      "metadata": {
        "id": "264532f1",
        "outputId": "d492a235-291f-4c62-89bc-926dff582dd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['성공의', '비결은', '단', '한', '가지', '잘할', '수', '있는', '일에', '광적으로', '집중하는', '것이다']"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = '성공의 비결은 단 한 가지, 잘할 수 있는 일에 광적으로 집중하는 것이다.'\n",
        "text_to_word_sequence(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33c5dc6",
      "metadata": {
        "id": "f33c5dc6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5bdf5b",
      "metadata": {
        "id": "fc5bdf5b",
        "outputId": "f433d7e9-8dea-4c59-81c5-4a6731d484dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'think': 6,\n",
              "  'like': 3,\n",
              "  'man': 4,\n",
              "  'of': 5,\n",
              "  'action': 1,\n",
              "  'and': 2,\n",
              "  'act': 0,\n",
              "  'thought': 7},\n",
              " array([[1, 1, 1, 2, 2, 2, 1, 1]]))"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = ['Think like a man of action and act like man of thought.']\n",
        "\n",
        "vector = CountVectorizer()\n",
        "bow = vector.fit_transform(corpus)\n",
        "vector.vocabulary_, bow.toarray(), "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63aa106e",
      "metadata": {
        "id": "63aa106e",
        "outputId": "08b46634-c202-4a16-c864-1b8564d5b34a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'think': 4, 'like': 2, 'man': 3, 'action': 1, 'act': 0, 'thought': 5},\n",
              " array([[1, 1, 2, 2, 1, 1]]))"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector = CountVectorizer(stop_words='english')\n",
        "bow = vector.fit_transform(corpus)\n",
        "vector.vocabulary_, bow.toarray(), "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7f12dc",
      "metadata": {
        "id": "0f7f12dc",
        "outputId": "978e9dd8-a1e5-4baf-80d6-d6228acca4a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'평생': 8,\n",
              "  '것처럼': 0,\n",
              "  '꿈을': 3,\n",
              "  '꾸어라': 2,\n",
              "  '그리고': 1,\n",
              "  '내일': 4,\n",
              "  '죽을': 7,\n",
              "  '오늘을': 6,\n",
              "  '살아라': 5},\n",
              " array([[2, 1, 1, 1, 1, 1, 1, 1, 1]]))"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = ['평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라.']\n",
        "vector = CountVectorizer()\n",
        "bow = vector.fit_transform(corpus)\n",
        "vector.vocabulary_, bow.toarray(), "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdd7b28",
      "metadata": {
        "id": "4fdd7b28"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from konlpy.tag import Mecab\n",
        "tagger = Mecab()\n",
        "\n",
        "corpus = '평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라.'\n",
        "tokens = tagger.morphs(re.sub('(\\.)','',corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1825a940",
      "metadata": {
        "id": "1825a940",
        "outputId": "d7d84e12-4bba-4228-fa57-4f081ad97f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'평생': 0,\n",
              "  '살': 1,\n",
              "  '것': 2,\n",
              "  '처럼': 3,\n",
              "  '꿈': 4,\n",
              "  '을': 5,\n",
              "  '꾸': 6,\n",
              "  '어라': 7,\n",
              "  '그리고': 8,\n",
              "  '내일': 9,\n",
              "  '죽': 10,\n",
              "  '오늘': 11,\n",
              "  '아라': 12},\n",
              " [1, 2, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = dict()\n",
        "bow = list()\n",
        "for tok in tokens:\n",
        "    if tok not in vocab.keys():\n",
        "        vocab[tok] = len(vocab)\n",
        "        bow.insert(len(vocab)-1, 1)\n",
        "    else :\n",
        "        index = vocab.get(tok)\n",
        "        bow[index] = bow[index]+1\n",
        "\n",
        "vocab, bow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27063173",
      "metadata": {
        "id": "27063173"
      },
      "source": [
        "DTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0105e1e",
      "metadata": {
        "id": "d0105e1e",
        "outputId": "3fd99695-0c5f-4c17-d493-b17a4e9f098a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'think': 15,\n",
              "  'like': 8,\n",
              "  'man': 9,\n",
              "  'of': 12,\n",
              "  'action': 1,\n",
              "  'and': 2,\n",
              "  'act': 0,\n",
              "  'thought': 16,\n",
              "  'try': 18,\n",
              "  'not': 11,\n",
              "  'to': 17,\n",
              "  'become': 3,\n",
              "  'success': 14,\n",
              "  'but': 4,\n",
              "  'rather': 13,\n",
              "  'value': 19,\n",
              "  'give': 6,\n",
              "  'me': 10,\n",
              "  'liberty': 7,\n",
              "  'death': 5},\n",
              " array([[1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1, 0, 0, 2, 2, 1],\n",
              "        [0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = ['Think like a man of action and act like man of thought.',\n",
        "         'Try not to become a man of success but rather try to become a man of value',\n",
        "         'Give me liberty, of give me death']\n",
        "\n",
        "vector = CountVectorizer()\n",
        "# vector = CountVectorizer(stop_words='english')\n",
        "\n",
        "bow = vector.fit_transform(corpus)\n",
        "vector.vocabulary_, bow.toarray(), "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e4dabd",
      "metadata": {
        "collapsed": true,
        "id": "61e4dabd",
        "outputId": "dfa66a5d-e87b-4278-c483-52a72fa23ae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['act',\n",
              " 'action',\n",
              " 'and',\n",
              " 'become',\n",
              " 'but',\n",
              " 'death',\n",
              " 'give',\n",
              " 'liberty',\n",
              " 'like',\n",
              " 'man',\n",
              " 'me',\n",
              " 'not',\n",
              " 'of',\n",
              " 'rather',\n",
              " 'success',\n",
              " 'think',\n",
              " 'thought',\n",
              " 'to',\n",
              " 'try',\n",
              " 'value']"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = list()\n",
        "for k,v in sorted(vector.vocabulary_.items(), key=lambda item:item[1]):\n",
        "    columns.append(k)\n",
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0304365",
      "metadata": {
        "id": "e0304365",
        "outputId": "34b16e4b-47a2-447c-d533-fc930c96bbff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>and</th>\n",
              "      <th>become</th>\n",
              "      <th>but</th>\n",
              "      <th>death</th>\n",
              "      <th>give</th>\n",
              "      <th>liberty</th>\n",
              "      <th>like</th>\n",
              "      <th>man</th>\n",
              "      <th>me</th>\n",
              "      <th>not</th>\n",
              "      <th>of</th>\n",
              "      <th>rather</th>\n",
              "      <th>success</th>\n",
              "      <th>think</th>\n",
              "      <th>thought</th>\n",
              "      <th>to</th>\n",
              "      <th>try</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   act  action  and  become  but  death  give  liberty  like  man  me  not  \\\n",
              "0    1       1    1       0    0      0     0        0     2    2   0    0   \n",
              "1    0       0    0       2    1      0     0        0     0    2   0    1   \n",
              "2    0       0    0       0    0      1     2        1     0    0   2    0   \n",
              "\n",
              "   of  rather  success  think  thought  to  try  value  \n",
              "0   2       0        0      1        1   0    0      0  \n",
              "1   2       1        1      0        0   2    2      1  \n",
              "2   1       0        0      0        0   0    0      0  "
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(bow.toarray(), columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26308328",
      "metadata": {
        "id": "26308328"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646a5008",
      "metadata": {
        "id": "646a5008"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf19befd",
      "metadata": {
        "collapsed": true,
        "id": "bf19befd",
        "outputId": "bf38216f-b410-4e7b-9b59-61e1d14b1618"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'think': 7,\n",
              "  'like': 4,\n",
              "  'man': 5,\n",
              "  'action': 1,\n",
              "  'act': 0,\n",
              "  'thought': 8,\n",
              "  'try': 9,\n",
              "  'success': 6,\n",
              "  'value': 10,\n",
              "  'liberty': 3,\n",
              "  'death': 2},\n",
              " array([[0.311383  , 0.311383  , 0.        , 0.        , 0.62276601,\n",
              "         0.4736296 , 0.        , 0.311383  , 0.311383  , 0.        ,\n",
              "         0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.52753275, 0.34682109, 0.        , 0.        , 0.69364217,\n",
              "         0.34682109],\n",
              "        [0.        , 0.        , 0.70710678, 0.70710678, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        ]]))"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english').fit(corpus)\n",
        "\n",
        "tfidf.vocabulary_, tfidf.transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0162f6c0",
      "metadata": {
        "id": "0162f6c0",
        "outputId": "124b1e5a-116d-4bcf-c8ff-6f27b685ef4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>death</th>\n",
              "      <th>liberty</th>\n",
              "      <th>like</th>\n",
              "      <th>man</th>\n",
              "      <th>success</th>\n",
              "      <th>think</th>\n",
              "      <th>thought</th>\n",
              "      <th>try</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.622766</td>\n",
              "      <td>0.473630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527533</td>\n",
              "      <td>0.346821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.346821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        act    action     death   liberty      like       man   success  \\\n",
              "0  0.311383  0.311383  0.000000  0.000000  0.622766  0.473630  0.000000   \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.527533  0.346821   \n",
              "2  0.000000  0.000000  0.707107  0.707107  0.000000  0.000000  0.000000   \n",
              "\n",
              "      think   thought       try     value  \n",
              "0  0.311383  0.311383  0.000000  0.000000  \n",
              "1  0.000000  0.000000  0.693642  0.346821  \n",
              "2  0.000000  0.000000  0.000000  0.000000  "
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_array = tfidf.transform(corpus).toarray()\n",
        "columns = list()\n",
        "for k,v in sorted(tfidf.vocabulary_.items(), key=lambda item:item[1]):\n",
        "    columns.append(k)\n",
        "# columns\n",
        "pd.DataFrame(tfidf_array, columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15833e30",
      "metadata": {
        "id": "15833e30"
      },
      "source": [
        "Semantic Network Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740ec1cc",
      "metadata": {
        "id": "740ec1cc",
        "outputId": "958fc331-4fc7-4b6d-bb29-5e0c964040ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68ff43a",
      "metadata": {
        "id": "a68ff43a",
        "outputId": "28931bee-2935-413f-a146-21a318465e97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/freesky/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f123ef9",
      "metadata": {
        "id": "0f123ef9",
        "outputId": "2e6fdfb2-bf40-4cc5-9854-dcb6750d6cc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I', 'love', 'data', 'science', 'and', 'deep', 'learning', '.']"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import word_tokenize, bigrams\n",
        "sentence = 'I love data science and deep learning.'\n",
        "tokens = word_tokenize(sentence)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37deca14",
      "metadata": {
        "id": "37deca14"
      },
      "source": [
        "# Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04956578",
      "metadata": {
        "id": "04956578",
        "outputId": "9d07f8e6-c74e-4b41-a850-ea786b91e8bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(sklearn.utils.Bunch,\n",
              " dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR']))"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7a2155",
      "metadata": {
        "id": "2c7a2155",
        "outputId": "2b57cc9e-d53a-4308-bb92-402bfc855feb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(sklearn.utils.Bunch,\n",
              " dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR']),\n",
              " ['alt.atheism',\n",
              "  'comp.graphics',\n",
              "  'comp.os.ms-windows.misc',\n",
              "  'comp.sys.ibm.pc.hardware',\n",
              "  'comp.sys.mac.hardware',\n",
              "  'comp.windows.x',\n",
              "  'misc.forsale',\n",
              "  'rec.autos',\n",
              "  'rec.motorcycles',\n",
              "  'rec.sport.baseball',\n",
              "  'rec.sport.hockey',\n",
              "  'sci.crypt',\n",
              "  'sci.electronics',\n",
              "  'sci.med',\n",
              "  'sci.space',\n",
              "  'soc.religion.christian',\n",
              "  'talk.politics.guns',\n",
              "  'talk.politics.mideast',\n",
              "  'talk.politics.misc',\n",
              "  'talk.religion.misc'])"
            ]
          },
          "execution_count": 57,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dataset), dataset.keys(), dataset.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cac3e1a",
      "metadata": {
        "id": "5cac3e1a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "news_df = pd.DataFrame({'article':dataset.data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc4e290",
      "metadata": {
        "id": "3bc4e290",
        "outputId": "43106be7-00d8-48c1-a0f2-b3fabb763ee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11314 entries, 0 to 11313\n",
            "Data columns (total 1 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   article  11314 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 88.5+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                                                  article\n",
              " count                                               11314\n",
              " unique                                              11314\n",
              " top     From: rolfe@dsuvax.dsu.edu (Tim Rolfe)\\nSubjec...\n",
              " freq                                                    1,\n",
              " None)"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news_df.describe(), news_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450c8ec3",
      "metadata": {
        "id": "450c8ec3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Natural Language Processing beginner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
